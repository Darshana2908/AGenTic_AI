{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bdc1288-2cc3-4aa2-bf98-977be18ddfaf",
   "metadata": {},
   "source": [
    "## Section 1\n",
    "##### Source : https://www.youtube.com/watch?v=vr_sJ4veYOY \n",
    "\n",
    "##### 1. Get Your Claude API Key\n",
    "###### You can get a Claude API key by signing up on Anthropic's developer platform:\n",
    "\n",
    "###### Go to: https://console.anthropic.com\n",
    "\n",
    "###### Sign up or log in.\n",
    "\n",
    "###### Navigate to API Keys from the dashboard (left bottom).\n",
    "\n",
    "###### Click \"Create Key\", and copy the generated key.\n",
    "\n",
    "##### 2. Store the API Key Securely\n",
    "###### Use a .env file to securely store the API key in your project directory.\n",
    "\n",
    "###### Steps:\n",
    "###### Create a file in your root project directory named .env.\n",
    "\n",
    "###### Add the following line to that .env file:\n",
    "###### ANTHROPIC_API_KEY=your_claude_api_key_here\n",
    "\n",
    "###### Replace your_claude_api_key_here with the actual key from the Claude dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1184f935-4a67-4f89-b314-fd77a9b889f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a8c597-36ef-4183-ac4b-a9d6caad64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install llama-index-llms-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924a33ba-42e6-42bd-98c8-7634399d9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "path_to_add = r\"C:\\Users\\darsh\\AppData\\Roaming\\Python\\Python312\\Scripts\"\n",
    "if path_to_add not in os.environ[\"PATH\"]:\n",
    "    os.environ[\"PATH\"] += os.pathsep + path_to_add\n",
    "    sys.path.append(path_to_add)\n",
    "\n",
    "print(\"Path added!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5c7a09-a34d-42e4-b71d-abd9d1a5d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade llama-index #Upgraded as i was getting the error as CodeInterpreterToolSpec not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd681dcd-a7a3-4c57-bd86-982f42325a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade llama-index-llms-anthropic #Upgraded as i was getting the error as CodeInterpreterToolSpec not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d147c-8aef-421c-9288-9cb6f9c2ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.code_interpreter.base import CodeInterpreterToolSpec #Checking to see if this module was installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c4360b-cfe9-4e92-b049-576dc536769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This version doesnt work - given only for explanation\n",
    "\n",
    "#Imports\n",
    "from llama_index.llms.anthropic import Anthropic\n",
    "from llama_index.core import Settings\n",
    "from llama_index.tools.code_interpreter.base import CodeInterpreterToolSpec\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import FunctionCallingAgent\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import yfinance as yf\n",
    "load_dotenv()\n",
    "\n",
    "## Note: I get error here :\n",
    "## ---------------------------------------------------------------------------\n",
    "## ModuleNotFoundError                       Traceback (most recent call last)\n",
    "## Cell In[3], line 1\n",
    "## ----> 1 from llama_index.tools.code_interpreter.base import CodeInterpreterToolSpec\n",
    "\n",
    "## ModuleNotFoundError: No module named 'llama_index.tools'\n",
    "\n",
    "## Reason: I found that the module doesn't exist in the latest public version of llama-index. It was either:\n",
    "## Part of a private/internal demo\n",
    "## Or hasn't yet been released to public packages\n",
    "\n",
    "#Code Interpretor\n",
    "code_spec = CodeInterpreterToolSpec()\n",
    "tools = code_spec.to_tool_list()\n",
    "\n",
    "#Tokenizer and calling the claude\n",
    "tokenizer = Anthropic().tokenizer\n",
    "Settings.tokenizer = tokenizer\n",
    "\n",
    "llm_claude = Anthropic(model=\"claude-3-5-sonnet-20241022\")\n",
    "\n",
    "#Define our agent\n",
    "agent = FunctionCallingAgent.from_tools(\n",
    "    tools,\n",
    "    llm=llm_claude,\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=False,\n",
    ")\n",
    "\n",
    "#Define the prompt\n",
    "ticker = \"PLTR\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Write Python code to:\n",
    "- Detect which date is today\n",
    "- Based on this date, fetch historical prices of {ticker} from the beginning of the month until today.\n",
    "- Analyze the last month prices\n",
    "\"\"\"\n",
    "\n",
    "#Run the agent\n",
    "resp = agent.chat(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff83a15b-a5ba-420a-b5e1-9a42b2502fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.63-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance) (2.32.3)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from yfinance) (4.3.8)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance) (2.4.2)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Downloading peewee-3.18.1.tar.gz (3.0 MB)\n",
      "     ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.5/3.0 MB 1.9 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 1.0/3.0 MB 2.0 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 1.6/3.0 MB 2.3 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 2.1/3.0 MB 2.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.9/3.0 MB 2.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.0/3.0 MB 2.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance) (4.12.3)\n",
      "Collecting curl_cffi>=0.7 (from yfinance)\n",
      "  Downloading curl_cffi-0.11.3-cp39-abi3-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance) (4.25.3)\n",
      "Collecting websockets>=13.0 (from yfinance)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (2.2.3)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.16.0)\n",
      "Downloading yfinance-0.2.63-py2.py3-none-any.whl (118 kB)\n",
      "Downloading curl_cffi-0.11.3-cp39-abi3-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.5/1.4 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.0/1.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.3/1.4 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Building wheels for collected packages: peewee\n",
      "  Building wheel for peewee (pyproject.toml): started\n",
      "  Building wheel for peewee (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for peewee: filename=peewee-3.18.1-py3-none-any.whl size=139097 sha256=57f521eeb8075888b69dd3a52c880fd651d54510784f14d54cee3f7e188b12f8\n",
      "  Stored in directory: c:\\users\\darsh\\appdata\\local\\pip\\cache\\wheels\\1a\\57\\6a\\bb71346381d0d911cd4ce3026f1fa720da76707e4f01cf27dd\n",
      "Successfully built peewee\n",
      "Installing collected packages: peewee, multitasking, websockets, curl_cffi, yfinance\n",
      "Successfully installed curl_cffi-0.11.3 multitasking-0.0.11 peewee-3.18.1 websockets-15.0.1 yfinance-0.2.63\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbfddc98-37ce-49f5-9384-7e66cd2226dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step da39f123-e554-4cc5-87fa-d87dadcbf60d. Step input: \n",
      "Write and execute Python code to:\n",
      "- Detect today's date\n",
      "- Fetch historical prices of PLTR from the beginning of the current month until today using yfinance\n",
      "- Analyze the price trend over the month\n",
      "Return a summary of your findings.\n",
      "\n",
      "Added user message to memory: \n",
      "Write and execute Python code to:\n",
      "- Detect today's date\n",
      "- Fetch historical prices of PLTR from the beginning of the current month until today using yfinance\n",
      "- Analyze the price trend over the month\n",
      "Return a summary of your findings.\n",
      "\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 50\u001b[0m\n\u001b[0;32m     41\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124mWrite and execute Python code to:\u001b[39m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124m- Detect today\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms date\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124mReturn a summary of your findings.\u001b[39m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m#Run the agent\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m response \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mchat(prompt)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:323\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    320\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 323\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    326\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\llama_index\\core\\callbacks\\utils.py:42\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m cast(CallbackManager, callback_manager)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m callback_manager\u001b[38;5;241m.\u001b[39mas_trace(trace_id):\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\llama_index\\core\\agent\\runner\\base.py:695\u001b[0m, in \u001b[0;36mAgentRunner.chat\u001b[1;34m(self, message, chat_history, tool_choice)\u001b[0m\n\u001b[0;32m    690\u001b[0m     tool_choice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_tool_choice\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    692\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mAGENT_STEP,\n\u001b[0;32m    693\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mMESSAGES: [message]},\n\u001b[0;32m    694\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 695\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chat(\n\u001b[0;32m    696\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[0;32m    697\u001b[0m         chat_history\u001b[38;5;241m=\u001b[39mchat_history,\n\u001b[0;32m    698\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[0;32m    699\u001b[0m         mode\u001b[38;5;241m=\u001b[39mChatResponseMode\u001b[38;5;241m.\u001b[39mWAIT,\n\u001b[0;32m    700\u001b[0m     )\n\u001b[0;32m    701\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chat_response, AgentChatResponse)\n\u001b[0;32m    702\u001b[0m     e\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mRESPONSE: chat_response})\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:323\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    320\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 323\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    326\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\llama_index\\core\\agent\\runner\\base.py:627\u001b[0m, in \u001b[0;36mAgentRunner._chat\u001b[1;34m(self, message, chat_history, tool_choice, mode)\u001b[0m\n\u001b[0;32m    624\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(AgentChatWithStepStartEvent(user_msg\u001b[38;5;241m=\u001b[39mmessage))\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# pass step queue in as argument, assume step executor is stateless\u001b[39;00m\n\u001b[1;32m--> 627\u001b[0m     cur_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_step(\n\u001b[0;32m    628\u001b[0m         task\u001b[38;5;241m.\u001b[39mtask_id, mode\u001b[38;5;241m=\u001b[39mmode, tool_choice\u001b[38;5;241m=\u001b[39mtool_choice\n\u001b[0;32m    629\u001b[0m     )\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cur_step_output\u001b[38;5;241m.\u001b[39mis_last:\n\u001b[0;32m    632\u001b[0m         result_output \u001b[38;5;241m=\u001b[39m cur_step_output\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:323\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    320\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 323\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    326\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\llama_index\\core\\agent\\runner\\base.py:423\u001b[0m, in \u001b[0;36mAgentRunner._run_step\u001b[1;34m(self, task_id, step, input, mode, **kwargs)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# TODO: figure out if you can dynamically swap in different step executors\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# not clear when you would do that by theoretically possible\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m ChatResponseMode\u001b[38;5;241m.\u001b[39mWAIT:\n\u001b[1;32m--> 423\u001b[0m     cur_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_worker\u001b[38;5;241m.\u001b[39mrun_step(step, task, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m ChatResponseMode\u001b[38;5;241m.\u001b[39mSTREAM:\n\u001b[0;32m    425\u001b[0m     cur_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_worker\u001b[38;5;241m.\u001b[39mstream_step(step, task, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:323\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    320\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 323\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    326\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\llama_index\\core\\callbacks\\utils.py:42\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m cast(CallbackManager, callback_manager)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m callback_manager\u001b[38;5;241m.\u001b[39mas_trace(trace_id):\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\llama_index\\core\\agent\\function_calling\\step.py:309\u001b[0m, in \u001b[0;36mFunctionCallingAgentWorker.run_step\u001b[1;34m(self, step, task, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m tools \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_tools(task\u001b[38;5;241m.\u001b[39minput)\n\u001b[0;32m    308\u001b[0m \u001b[38;5;66;03m# get response and tool call (if exists)\u001b[39;00m\n\u001b[1;32m--> 309\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mchat_with_tools(\n\u001b[0;32m    310\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[0;32m    311\u001b[0m     user_msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    312\u001b[0m     chat_history\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_messages(task),\n\u001b[0;32m    313\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbose,\n\u001b[0;32m    314\u001b[0m     allow_parallel_tool_calls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_parallel_tool_calls,\n\u001b[0;32m    315\u001b[0m )\n\u001b[0;32m    316\u001b[0m tool_calls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mget_tool_calls_from_response(\n\u001b[0;32m    317\u001b[0m     response, error_on_no_tool_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    318\u001b[0m )\n\u001b[0;32m    319\u001b[0m tool_outputs: List[ToolOutput] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\llama_index\\core\\llms\\function_calling.py:55\u001b[0m, in \u001b[0;36mFunctionCallingLLM.chat_with_tools\u001b[1;34m(self, tools, user_msg, chat_history, verbose, allow_parallel_tool_calls, tool_required, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Chat with function calling.\"\"\"\u001b[39;00m\n\u001b[0;32m     46\u001b[0m chat_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_chat_with_tools_compat(\n\u001b[0;32m     47\u001b[0m     tools,\n\u001b[0;32m     48\u001b[0m     user_msg\u001b[38;5;241m=\u001b[39muser_msg,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     54\u001b[0m )\n\u001b[1;32m---> 55\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mchat_kwargs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_chat_with_tools_response(\n\u001b[0;32m     57\u001b[0m     response,\n\u001b[0;32m     58\u001b[0m     tools,\n\u001b[0;32m     59\u001b[0m     allow_parallel_tool_calls\u001b[38;5;241m=\u001b[39mallow_parallel_tool_calls,\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     61\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:323\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    320\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 323\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    326\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\llama_index\\core\\llms\\callbacks.py:175\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[1;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[0;32m    167\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[0;32m    168\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    172\u001b[0m     },\n\u001b[0;32m    173\u001b[0m )\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m f(_self, messages, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    177\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[0;32m    178\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[0;32m    179\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[0;32m    180\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[0;32m    181\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\llama_index\\llms\\anthropic\\base.py:361\u001b[0m, in \u001b[0;36mAnthropic.chat\u001b[1;34m(self, messages, **kwargs)\u001b[0m\n\u001b[0;32m    356\u001b[0m anthropic_messages, system_prompt \u001b[38;5;241m=\u001b[39m messages_to_anthropic_messages(\n\u001b[0;32m    357\u001b[0m     messages, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_idx\n\u001b[0;32m    358\u001b[0m )\n\u001b[0;32m    359\u001b[0m all_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_all_kwargs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 361\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    362\u001b[0m     messages\u001b[38;5;241m=\u001b[39manthropic_messages,\n\u001b[0;32m    363\u001b[0m     stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    364\u001b[0m     system\u001b[38;5;241m=\u001b[39msystem_prompt,\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mall_kwargs,\n\u001b[0;32m    366\u001b[0m )\n\u001b[0;32m    368\u001b[0m content, tool_calls, thinking, citations \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_content_and_tool_calls_and_thinking(response)\n\u001b[0;32m    370\u001b[0m )\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m AnthropicChatResponse(\n\u001b[0;32m    373\u001b[0m     message\u001b[38;5;241m=\u001b[39mChatMessage(\n\u001b[0;32m    374\u001b[0m         role\u001b[38;5;241m=\u001b[39mMessageRole\u001b[38;5;241m.\u001b[39mASSISTANT,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(response),\n\u001b[0;32m    383\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\anthropic\\_utils\\_utils.py:283\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    281\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\anthropic\\resources\\messages\\messages.py:978\u001b[0m, in \u001b[0;36mMessages.create\u001b[1;34m(self, max_tokens, messages, model, metadata, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[0;32m    972\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    973\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m    975\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    976\u001b[0m     )\n\u001b[1;32m--> 978\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/v1/messages\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    980\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    981\u001b[0m         {\n\u001b[0;32m    982\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    983\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    984\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    985\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    986\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m    987\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop_sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop_sequences,\n\u001b[0;32m    988\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    989\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m: system,\n\u001b[0;32m    990\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    991\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthinking\u001b[39m\u001b[38;5;124m\"\u001b[39m: thinking,\n\u001b[0;32m    992\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    993\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    994\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_k,\n\u001b[0;32m    995\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    996\u001b[0m         },\n\u001b[0;32m    997\u001b[0m         message_create_params\u001b[38;5;241m.\u001b[39mMessageCreateParamsStreaming\n\u001b[0;32m    998\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[0;32m    999\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m message_create_params\u001b[38;5;241m.\u001b[39mMessageCreateParamsNonStreaming,\n\u001b[0;32m   1000\u001b[0m     ),\n\u001b[0;32m   1001\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m   1002\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m   1003\u001b[0m     ),\n\u001b[0;32m   1004\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mMessage,\n\u001b[0;32m   1005\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1006\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mStream[RawMessageStreamEvent],\n\u001b[0;32m   1007\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\anthropic\\_base_client.py:1307\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1295\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1302\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1303\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1304\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1305\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1306\u001b[0m     )\n\u001b[1;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\anthropic\\_base_client.py:1102\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1099\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1101\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1102\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "from llama_index.llms.anthropic import Anthropic\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.agent import FunctionCallingAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from dotenv import load_dotenv\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "#Load the env file\n",
    "load_dotenv()\n",
    "\n",
    "#Define a function to interpret code dynamically\n",
    "def run_code(prompt: str) -> str:\n",
    "    # Replace this with a secure sandbox in production!\n",
    "    local_vars = {}\n",
    "    try:\n",
    "        exec(prompt, {\"yf\": yf, \"datetime\": datetime}, local_vars)\n",
    "        return str(local_vars)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "#Wrap it in a FunctionTool\n",
    "code_tool = FunctionTool.from_defaults(fn=run_code)\n",
    "\n",
    "#Set up Claude\n",
    "llm_claude = Anthropic(model=\"claude-3-sonnet-20240229\")\n",
    "Settings.llm = llm_claude\n",
    "\n",
    "#Define the agent\n",
    "agent = FunctionCallingAgent.from_tools(\n",
    "    tools=[code_tool],\n",
    "    llm=llm_claude,\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=False,\n",
    ")\n",
    "\n",
    "#Ask the agent to run Python code\n",
    "ticker = \"PLTR\"\n",
    "prompt = f\"\"\"\n",
    "Write and execute Python code to:\n",
    "- Detect today's date\n",
    "- Fetch historical prices of {ticker} from the beginning of the current month until today using yfinance\n",
    "- Analyze the price trend over the month\n",
    "Return a summary of your findings.\n",
    "\"\"\"\n",
    "\n",
    "#Run the agent\n",
    "response = agent.chat(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226722b5-d0b0-42f6-8380-bf75c94a252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://console.anthropic.com/settings/billing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f9209-289b-41b7-babf-45758aa33b39",
   "metadata": {},
   "source": [
    "## Section - 2\n",
    "### We will use PhiData or https://www.agno.com/\n",
    "##### This is an open source framework that allows us to build, ship and monitor Agentic systems.\n",
    "##### We can build AI Agents, Multi - model agents, build complex agentic workflows, monitor them and deploy them.\n",
    "##### Source : https://www.youtube.com/watch?v=74SnvbQYgx8&t=580s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a9a606-3284-4300-95fc-e6d1f189dba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: phidata in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 1)) (2.7.10)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: yfinance in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 3)) (0.2.63)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (24.1)\n",
      "Requirement already satisfied: duckduckgo-search in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 5)) (8.0.3)\n",
      "Requirement already satisfied: fastapi in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 6)) (0.115.12)\n",
      "Requirement already satisfied: uvicorn in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 7)) (0.34.3)\n",
      "Requirement already satisfied: groq in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 8)) (0.28.0)\n",
      "Requirement already satisfied: openai in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 9)) (1.86.0)\n",
      "Requirement already satisfied: docstring-parser in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from phidata->-r requirements.txt (line 1)) (0.16)\n",
      "Requirement already satisfied: gitpython in c:\\programdata\\anaconda3\\lib\\site-packages (from phidata->-r requirements.txt (line 1)) (3.1.43)\n",
      "Requirement already satisfied: httpx in c:\\programdata\\anaconda3\\lib\\site-packages (from phidata->-r requirements.txt (line 1)) (0.27.0)\n",
      "Requirement already satisfied: pydantic in c:\\programdata\\anaconda3\\lib\\site-packages (from phidata->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pydantic-settings in c:\\programdata\\anaconda3\\lib\\site-packages (from phidata->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from phidata->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from phidata->-r requirements.txt (line 1)) (13.7.1)\n",
      "Requirement already satisfied: tomli in c:\\programdata\\anaconda3\\lib\\site-packages (from phidata->-r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: typer in c:\\programdata\\anaconda3\\lib\\site-packages (from phidata->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from phidata->-r requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance->-r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance->-r requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance->-r requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from yfinance->-r requirements.txt (line 3)) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from yfinance->-r requirements.txt (line 3)) (4.3.8)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance->-r requirements.txt (line 3)) (2.4.2)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from yfinance->-r requirements.txt (line 3)) (3.18.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance->-r requirements.txt (line 3)) (4.12.3)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from yfinance->-r requirements.txt (line 3)) (0.11.3)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from yfinance->-r requirements.txt (line 3)) (4.25.3)\n",
      "Requirement already satisfied: websockets>=13.0 in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from yfinance->-r requirements.txt (line 3)) (15.0.1)\n",
      "Requirement already satisfied: click>=8.1.8 in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from duckduckgo-search->-r requirements.txt (line 5)) (8.2.1)\n",
      "Requirement already satisfied: primp>=0.15.0 in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from duckduckgo-search->-r requirements.txt (line 5)) (0.15.0)\n",
      "Requirement already satisfied: lxml>=5.3.0 in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from duckduckgo-search->-r requirements.txt (line 5)) (5.4.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from fastapi->-r requirements.txt (line 6)) (0.46.2)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from uvicorn->-r requirements.txt (line 7)) (0.14.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from groq->-r requirements.txt (line 8)) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from groq->-r requirements.txt (line 8)) (1.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from groq->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\darsh\\appdata\\roaming\\python\\python312\\site-packages (from openai->-r requirements.txt (line 9)) (0.10.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai->-r requirements.txt (line 9)) (4.66.5)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->groq->-r requirements.txt (line 8)) (3.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance->-r requirements.txt (line 3)) (2.5)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click>=8.1.8->duckduckgo-search->-r requirements.txt (line 5)) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from curl_cffi>=0.7->yfinance->-r requirements.txt (line 3)) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from curl_cffi>=0.7->yfinance->-r requirements.txt (line 3)) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx->phidata->-r requirements.txt (line 1)) (1.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance->-r requirements.txt (line 3)) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic->phidata->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic->phidata->-r requirements.txt (line 1)) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance->-r requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gitpython->phidata->-r requirements.txt (line 1)) (4.0.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->phidata->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->phidata->-r requirements.txt (line 1)) (2.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance->-r requirements.txt (line 3)) (2.21)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython->phidata->-r requirements.txt (line 1)) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->phidata->-r requirements.txt (line 1)) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance->-r requirements.txt (line 3)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#Installing the required libraries\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbfb152c-e37b-41b8-ad26-57e2038116f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (140349413.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    set GROQ_API_KEY=\"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\"\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "set GROQ_API_KEY=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4fe9c43-5a06-4dfd-8826-985844890d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70ef9a06f0b452fa8aa6fd8236e4889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 48\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m#Above are two independent Agents\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#Multi-AI Agent : If we combine the above two agents, it will become multi-ai agent\u001b[39;00m\n\u001b[0;32m     41\u001b[0m multi_ai_agent\u001b[38;5;241m=\u001b[39mAgent(\n\u001b[0;32m     42\u001b[0m     team\u001b[38;5;241m=\u001b[39m[web_search_agent,finance_agent],\n\u001b[0;32m     43\u001b[0m     instructions\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlways include sources\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse tables to display the data\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     44\u001b[0m     show_tool_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     45\u001b[0m     markdown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     46\u001b[0m )\n\u001b[1;32m---> 48\u001b[0m multi_ai_agent\u001b[38;5;241m.\u001b[39mprint_response(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarize analyst recommendations and share the latest news for NVDA\u001b[39m\u001b[38;5;124m\"\u001b[39m, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\phi\\agent\\agent.py:2825\u001b[0m, in \u001b[0;36mAgent.print_response\u001b[1;34m(self, message, messages, stream, markdown, show_message, show_reasoning, show_full_reasoning, console, **kwargs)\u001b[0m\n\u001b[0;32m   2822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m render:\n\u001b[0;32m   2823\u001b[0m     live_log\u001b[38;5;241m.\u001b[39mupdate(Group(\u001b[38;5;241m*\u001b[39mpanels))\n\u001b[1;32m-> 2825\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(message\u001b[38;5;241m=\u001b[39mmessage, messages\u001b[38;5;241m=\u001b[39mmessages, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   2826\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp, RunResponse) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   2827\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mevent \u001b[38;5;241m==\u001b[39m RunEvent\u001b[38;5;241m.\u001b[39mrun_response:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\phi\\agent\\agent.py:1805\u001b[0m, in \u001b[0;36mAgent._run\u001b[1;34m(self, message, stream, audio, images, videos, messages, stream_intermediate_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream:\n\u001b[0;32m   1804\u001b[0m     model_response \u001b[38;5;241m=\u001b[39m ModelResponse(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1805\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model_response_chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mresponse_stream(messages\u001b[38;5;241m=\u001b[39mmessages_for_model):\n\u001b[0;32m   1806\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m model_response_chunk\u001b[38;5;241m.\u001b[39mevent \u001b[38;5;241m==\u001b[39m ModelResponseEvent\u001b[38;5;241m.\u001b[39massistant_response\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[0;32m   1807\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m model_response_chunk\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m model_response\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\phi\\model\\openai\\chat.py:872\u001b[0m, in \u001b[0;36mOpenAIChat.response_stream\u001b[1;34m(self, messages)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;66;03m# -*- Generate response\u001b[39;00m\n\u001b[0;32m    871\u001b[0m metrics\u001b[38;5;241m.\u001b[39mresponse_timer\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m--> 872\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke_stream(messages\u001b[38;5;241m=\u001b[39mmessages):\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    874\u001b[0m         metrics\u001b[38;5;241m.\u001b[39mcompletion_tokens \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\phi\\model\\openai\\chat.py:396\u001b[0m, in \u001b[0;36mOpenAIChat.invoke_stream\u001b[1;34m(self, messages)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke_stream\u001b[39m(\u001b[38;5;28mself\u001b[39m, messages: List[Message]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ChatCompletionChunk]:\n\u001b[0;32m    387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03m    Send a streaming chat completion request to the OpenAI API.\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;124;03m        Iterator[ChatCompletionChunk]: An iterator of chat completion chunks.\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 396\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_client()\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    397\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m    398\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_message(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages],  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    399\u001b[0m         stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    400\u001b[0m         stream_options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_usage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m},\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_kwargs,\n\u001b[0;32m    402\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_utils\\_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    922\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    923\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    924\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    927\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    928\u001b[0m             {\n\u001b[0;32m    929\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    930\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    931\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[0;32m    932\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    933\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    934\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    935\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    936\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    937\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m    938\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    939\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    940\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[0;32m    941\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    942\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    943\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[0;32m    944\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    945\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[0;32m    946\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    947\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    948\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m    949\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    950\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m    951\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    952\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m    953\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    954\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    955\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    956\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    957\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    958\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    959\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[0;32m    960\u001b[0m             },\n\u001b[0;32m    961\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsStreaming\n\u001b[0;32m    962\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[0;32m    963\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsNonStreaming,\n\u001b[0;32m    964\u001b[0m         ),\n\u001b[0;32m    965\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    966\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    967\u001b[0m         ),\n\u001b[0;32m    968\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    969\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    970\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    971\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1241\u001b[0m     )\n\u001b[1;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_base_client.py:1037\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1034\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1036\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1037\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "from phi.agent import Agent\n",
    "from phi.model.groq import Groq\n",
    "from phi.tools.yfinance import YFinanceTools\n",
    "from phi.tools.duckduckgo import DuckDuckGo\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() #Load env vars from env file\n",
    "#openai.api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#Define the Agents\n",
    "\n",
    "#This is a basic web search independent agent\n",
    "#How this agent works - When the agent is called, it hits the given tool, use the model defined with prompt provided as role and give us the response.\n",
    "#For how our response should be, we give the instructions and also convert it to markdown.\n",
    "## Where do i get these parameters from - check the documentation of phidata - https://docs.agno.com/tools/toolkits/others/yfinance#yfinance\n",
    "web_search_agent=Agent(\n",
    "    name=\"Web Search Agent\",\n",
    "    role=\"Search the web for the imformation\",\n",
    "    model=Groq(id=\"llama3-groq-70b-8192-tool-use-preview\"),\n",
    "    tools=[DuckDuckGo()], #Multiple tools can be passed here\n",
    "    instructions=[\"Always include sources\"],\n",
    "    show_tool_call=True,\n",
    "    markdown=True,\n",
    ")\n",
    "\n",
    "#This is a basic Financial Analyst independent Agent\n",
    "finance_agent=Agent(\n",
    "    name=\"Finance Analyst AI Agent\",\n",
    "    model=Groq(id=\"llama3-groq-70b-8192-tool-use-preview\"),\n",
    "    tools=[\n",
    "        YFinanceTools(stock_price=True, analyst_recommendations=True, stock_fundamentals=True, company_news=True),\n",
    "    ],\n",
    "    instructions=[\"Use tables to display the data\"],\n",
    "    show_tool_calls=True,\n",
    "    markdown=True,\n",
    ")\n",
    "\n",
    "#Above are two independent Agents\n",
    "\n",
    "#Multi-AI Agent : If we combine the above two agents, it will become multi-ai agent\n",
    "multi_ai_agent=Agent(\n",
    "    team=[web_search_agent,finance_agent],\n",
    "    instructions=[\"Always include sources\",\"Use tables to display the data\"],\n",
    "    show_tool_call=True,\n",
    "    markdown=True,\n",
    ")\n",
    "\n",
    "multi_ai_agent.print_response(\"Summarize analyst recommendations and share the latest news for NVDA\", stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051fdb14-0f75-4cbd-987d-36435e9c429c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
